{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdJ9hLSk2jHJcPlojSy1+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NefChr/Test7/blob/main/IPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D_cue5W6yOFk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "\n",
        "epochs = 100\n",
        "nclass = 12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadDataset():\n",
        "    filename = 'https://raw.githubusercontent.com/kdemertzis/EKPA/main/Data/pcap_data.csv'\n",
        "    trainfile = pd.read_csv(filename)\n",
        "    data = pd.DataFrame(trainfile).to_numpy()\n",
        "    data = data[data[:, 67] != 'DrDoS_LDAP']\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    label = data[:, 67].astype('str')\n",
        "    label_map = {\n",
        "        'WebDDoS': 0,\n",
        "        'BENIGN': 1,\n",
        "        'UDP-lag': 2,\n",
        "        'DrDoS_NTP': 3,\n",
        "        'Syn': 4,\n",
        "        'DrDoS_SSDP': 5,\n",
        "        'DrDoS_UDP': 6,\n",
        "        'DrDoS_NetBIOS': 7,\n",
        "        'DrDoS_MSSQL': 8,\n",
        "        'DrDoS_SNMP': 9,\n",
        "        'TFTP': 10,\n",
        "        'DrDoS_DNS': 11\n",
        "    }\n",
        "    label = np.array([label_map[l] for l in label])\n",
        "\n",
        "    inx_sel = np.array([38, 47, 37, 48, 11, 9, 7, 52, 10, 36, 1, 34, 4, 17, 19, 57, 21,\n",
        "                        18, 22, 24, 32, 50, 23, 55, 51, 5, 3, 39, 40, 43, 58, 12, 25,\n",
        "                        20, 2, 35, 67, 33, 6, 53]) - 1\n",
        "\n",
        "    data = data[:, inx_sel]\n",
        "    dmin = data.min(axis=0)\n",
        "    dmax = data.max(axis=0)\n",
        "    data = (data - dmin) / (dmax - dmin)\n",
        "\n",
        "    train_data, test_data, train_label, test_label = \\\n",
        "        train_test_split(data, label, test_size=0.20, stratify=label)\n",
        "\n",
        "    train_data, val_data, train_label, val_label = \\\n",
        "        train_test_split(train_data, train_label, test_size=0.125, stratify=train_label)\n",
        "\n",
        "    return train_data.astype('float32'), train_label.astype('int32'), \\\n",
        "        val_data.astype('float32'), val_label.astype('int32'), \\\n",
        "        test_data.astype('float32'), test_label.astype('int32')\n"
      ],
      "metadata": {
        "id": "uh9_9IbHyrl_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labelp, val_data, val_labelp, test_data, test_labelp = loadDataset()\n",
        "\n",
        "train_label = to_categorical(train_labelp, nclass)\n",
        "val_label = to_categorical(val_labelp, nclass)\n",
        "test_label = to_categorical(test_labelp, nclass)"
      ],
      "metadata": {
        "id": "0VvA06FO4ZJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inshape = train_data.shape[1]\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                  classes=np.unique(train_labelp),\n",
        "                                                  y=train_labelp)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='min')\n",
        "\n",
        "modelCheckPoint = ModelCheckpoint('./savemodels/model5class.weights.{epoch:03d}-{val_acc:.4f}.hdf5',\n",
        "                                  save_best_only=True, monitor='val_acc', mode='max')\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(64, 3, activation='relu', input_shape=(inshape, 1)),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(64, 3, activation='relu'),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(nclass, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "rba-_cq-4bNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data.reshape(-1, inshape, 1),\n",
        "                    train_label,\n",
        "                    shuffle=True,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=256,\n",
        "                    validation_data=(val_data.reshape(-1, inshape, 1), val_label),\n",
        "                    callbacks=[modelCheckPoint],\n",
        "                    class_weight=class_weights,\n",
        "                    workers=3)\n",
        "\n",
        "str_models = os.listdir('./savemodels')\n",
        "str_models = np.sort(str_models)\n",
        "best_model = str_models[-1]\n",
        "model.load_weights('./savemodels/' + best_model)\n",
        "\n",
        "print('TEST DATA-Confusion matrix:')\n",
        "pred = model.predict(test_data.reshape(-1, inshape, 1))\n",
        "pred_y = pred.argmax(axis=-1)\n",
        "\n",
        "cm = confusion_matrix(test_labelp.astype('int32'), pred_y)\n",
        "print(cm)\n",
        "\n",
        "label = np.array([\"WebDDoS\", \"BENIGN\", \"UDP-lag\", \"DrDoS_NTP\", \"Syn\",\n",
        "                  \"DrDoS_SSDP\", \"DrDoS_UDP\", \"DrDoS_NetBIOS\", \"DrDoS_MSSQL\",\n",
        "                  \"DrDoS_SNMP\", \"TFTP\", \"DrDoS_DNS\"])\n",
        "\n",
        "print('Accuracy ratios for each class')\n",
        "for i in range(nclass):\n",
        "    print(label[i], '=', cm[i, i] / np.sum(cm[i, :]))"
      ],
      "metadata": {
        "id": "MSWAwzMh4eS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Blocking traffic simulation\n",
        "threshold = 0.5\n",
        "malicious_indices = np.where(pred.max(axis=1) > threshold)[0]\n",
        "print(\"Malicious traffic indices:\", malicious_indices)"
      ],
      "metadata": {
        "id": "PbCTHHos4jK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate blocking action\n",
        "for idx in malicious_indices:\n",
        "    print(\"Blocking traffic with index:\", idx)"
      ],
      "metadata": {
        "id": "qjvsSzvE4mws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "DX1mDnch4omS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v9DIj1pP4q1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}